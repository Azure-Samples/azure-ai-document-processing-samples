{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction - Azure AI Document Intelligence + Phi-3.5-mini\n",
    "\n",
    "This sample demonstrates how to extract structured data from any document using Azure AI Document Intelligence and small language models, such as Microsoft's Phi-3.5-mini.\n",
    "\n",
    "This is achieved by the following process:\n",
    "\n",
    "- Analyze a document using Azure AI Document Intelligence's `prebuilt-layout` model to extract the structure as Markdown.\n",
    "- Construct a system prompt that defines the instruction for extracting structured data from documents.\n",
    "- Construct a user prompt that includes specific extraction instruction for the type of document, the expected JSON schema, and the Markdown content of the document\n",
    "- Use the chat completions API with the Phi-3.5-mini model to generate a structured output from the content.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this sample, you will have learned how to:\n",
    "\n",
    "- Convert a document to Markdown format using Azure AI Document Intelligence.\n",
    "- Use prompt engineering techniques to instruct Phi-3.5-mini to extract structured data from a type of document using example JSON structures.\n",
    "- Use the analysis result from Azure AI Document Intelligence to determine the confidence of the extracted structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules\n",
    "\n",
    "This sample takes advantage of the following Python dependencies:\n",
    "\n",
    "- **azure-ai-documentintelligence** to interface with the Azure AI Document Intelligence API for analyzing documents.\n",
    "- **openai** to use the default OpenAI client implementation to interface with a deployed Phi-3.5-mini serverless endpoint in Azure AI Studio. _Note: The serverless endpoint for Phi-3.5-mini uses the same API schema as the OpenAI API._\n",
    "- **azure-identity** to securely authenticate with deployed Azure Services using Microsoft Entra ID credentials.\n",
    "\n",
    "The following local modules are also used:\n",
    "\n",
    "- **modules.app_settings** to access environment variables from the `.env` file.\n",
    "- **modules.comparison** to compare the output of the extraction process with expected results.\n",
    "- **modules.document_intelligence_confidence** to evaluate the confidence of the extraction process based on the extracted structured output and the analysis result from Azure AI Document Intelligence.\n",
    "- **modules.document_processing_result** to store the results of the extraction process as a file.\n",
    "- **modules.invoice** to provide the expected structured output JSON schema for invoice documents.\n",
    "- **modules.stopwatch** to measure the end-to-end execution time for the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../') # Import local modules\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, ContentFormat\n",
    "from openai import OpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from modules.app_settings import AppSettings\n",
    "from modules.comparison import extraction_comparison\n",
    "from modules.document_intelligence_confidence import evaluate_confidence\n",
    "from modules.document_processing_result import DataExtractionResult\n",
    "from modules.invoice import Invoice, InvoiceProduct, InvoiceSignature, InvoiceEvaluator\n",
    "from modules.stopwatch import Stopwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Azure services\n",
    "\n",
    "To use Azure AI Document Intelligence and a serverless model endpoint deployment, their SDKs are used to create client instances using a deployed endpoint and authentication credentials.\n",
    "\n",
    "For this sample, the credentials of the Azure CLI are used to authenticate with Azure AI Document Intelligence. The OpenAI client for the Phi-3.5-mini model uses an API key to authenticate with the serverless endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to the root of the repo\n",
    "working_dir = os.path.abspath('../../../')\n",
    "settings = AppSettings(dotenv_values(f\"{working_dir}/.env\"))\n",
    "\n",
    "# Configure the default credential for accessing Azure services using Azure CLI credentials\n",
    "credential = DefaultAzureCredential(\n",
    "    exclude_workload_identity_credential=True,\n",
    "    exclude_developer_cli_credential=True,\n",
    "    exclude_environment_credential=True,\n",
    "    exclude_managed_identity_credential=True,\n",
    "    exclude_powershell_credential=True,\n",
    "    exclude_shared_token_cache_credential=True,\n",
    "    exclude_interactive_browser_credential=True\n",
    ")\n",
    "\n",
    "# The serverless endpoint for Phi-3.5-mini uses the same API as OpenAI so we can use the OpenAI client\n",
    "openai_client = OpenAI(\n",
    "    base_url=settings.phi35_mini_endpoint,\n",
    "    api_key=settings.phi35_mini_primary_key,\n",
    ")\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=settings.ai_services_endpoint,\n",
    "    credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish the expected output\n",
    "\n",
    "To compare the accuracy of the extraction process, the expected output of the extraction process has been defined in the following code block based on the details of the [Invoice](../../assets/Invoice.pdf).\n",
    "\n",
    "The expected output has been defined by a human evaluating the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = f\"{working_dir}/samples/assets/\"\n",
    "pdf_file_name = \"Invoice.pdf\"\n",
    "fname = f\"{pdf_path}{pdf_file_name}\"\n",
    "\n",
    "expected = Invoice(\n",
    "    invoice_number='3847193',\n",
    "    purchase_order_number='15931',\n",
    "    customer_name='Sharp Consulting',\n",
    "    customer_address='73 Regal Way, Leeds, LS1 5AB, UK',\n",
    "    delivery_date='2024-05-16',\n",
    "    payable_by='2024-05-24',\n",
    "    products=[\n",
    "        InvoiceProduct(\n",
    "            id='MA197',\n",
    "            description='STRETCHWRAP ROLL',\n",
    "            unit_price=16.62,\n",
    "            quantity=5,\n",
    "            total=83.10,\n",
    "            reason=None\n",
    "        ),\n",
    "        InvoiceProduct(\n",
    "            id='ST4086',\n",
    "            description='BALLPOINT PEN MED.',\n",
    "            unit_price=2.49,\n",
    "            quantity=10,\n",
    "            total=24.90,\n",
    "            reason=None\n",
    "        ),\n",
    "        InvoiceProduct(\n",
    "            id='JF9912413BF',\n",
    "            description='BUBBLE FILM ROLL CL.',\n",
    "            unit_price=15.46,\n",
    "            quantity=12,\n",
    "            total=185.52,\n",
    "            reason=None\n",
    "        ),\n",
    "    ],\n",
    "    returns=[\n",
    "        InvoiceProduct(\n",
    "            id='MA145',\n",
    "            description='POSTAL TUBE BROWN',\n",
    "            unit_price=None,\n",
    "            quantity=1,\n",
    "            total=None,\n",
    "            reason='This item was provided in previous order as a replacement'\n",
    "        ),\n",
    "        InvoiceProduct(\n",
    "            id='JF7902',\n",
    "            description='MAILBOX 25PK',\n",
    "            unit_price=None,\n",
    "            quantity=1,\n",
    "            total=None,\n",
    "            reason='Not required'\n",
    "        ),\n",
    "    ],\n",
    "    total_product_quantity=27,\n",
    "    total_product_price=293.52,\n",
    "    product_signatures=[\n",
    "        InvoiceSignature(\n",
    "            type='Customer',\n",
    "            name='Sarah H',\n",
    "            is_signed=True\n",
    "        ),\n",
    "        InvoiceSignature(\n",
    "            type='Driver',\n",
    "            name='James T',\n",
    "            is_signed=True\n",
    "        )\n",
    "    ],\n",
    "    returns_signatures=[\n",
    "        InvoiceSignature(\n",
    "            type='Customer',\n",
    "            name='Sarah H',\n",
    "            is_signed=True\n",
    "        ),\n",
    "        InvoiceSignature(\n",
    "            type='Driver',\n",
    "            name='James T',\n",
    "            is_signed=True\n",
    "        )\n",
    "    ]   \n",
    ")\n",
    "\n",
    "invoice_evaluator = InvoiceEvaluator(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from the document\n",
    "\n",
    "The following code block executes the data extraction process using Azure AI Document Intelligence and Phi-3.5-mini.\n",
    "\n",
    "It performs the following steps:\n",
    "\n",
    "1. Get the document bytes from the provided file path. _Note: In this example, we are processing a local document, however, you can use any document storage location of your choice, such as Azure Blob Storage._\n",
    "2. Use Azure AI Document Intelligence to analyze the structure of the document and convert it to Markdown format using the pre-built layout model.\n",
    "3. Using a Phi-3.5-mini Serverless Endpoint model deployment in Azure AI Studio and prompt engineering techniques, extract a structured data transfer object (DTO) from the content of the Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Stopwatch() as di_stopwatch:\n",
    "    with open(fname, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\",\n",
    "            analyze_request=f,\n",
    "            output_content_format=ContentFormat.MARKDOWN,\n",
    "            content_type=\"application/pdf\"\n",
    "        )\n",
    "        \n",
    "    result: AnalyzeResult = poller.result()\n",
    "\n",
    "markdown = result.content\n",
    "\n",
    "with Stopwatch() as oai_stopwatch:\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=settings.gpt4o_model_deployment_name,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant that extracts data from documents and returns them as structured JSON objects.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Extract the data from this invoice. \n",
    "                - If a value is not present, provide null.\n",
    "                - **Do not return as a JSON code block.**\n",
    "                - Use the following structure: {json.dumps(Invoice.example().to_dict())}\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": markdown,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1,\n",
    "        top_p=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the outputs\n",
    "\n",
    "To provide context for the execution of the code, the following code blocks visualize the outputs of the data extraction process.\n",
    "\n",
    "This includes:\n",
    "\n",
    "- The Markdown representation of the document structure as determined by Azure AI Document Intelligence.\n",
    "- The accuracy of the structured data extraction comparing the expected output with the output generated by Phi-3.5-mini.\n",
    "- The confidence score of the structured data extraction by comparing against the Azure AI Document Intelligence analysis.\n",
    "- The execution time of the end-to-end process.\n",
    "- The total number of tokens consumed by the Phi-3.5-mini model.\n",
    "- The side-by-side comparison of the expected output and the output generated by Phi-3.5-mini.\n",
    "\n",
    "### Understanding Accuracy vs Confidence\n",
    "\n",
    "When using AI to extract structured data, both confidence and accuracy are essential for different but complementary reasons.\n",
    "\n",
    "- **Accuracy** measures how close the AI model's output is to a ground truth or expected output. It reflects how well the model's predictions align with reality.\n",
    "  - Accuracy ensures consistency in the extraction process, which is crucial for downstream tasks using the data.\n",
    "- **Confidence** represents the AI model's internal assessment of how certain it is about its predictions.\n",
    "  - Confidence indicates that the model is certain about its predictions, which can be a useful indicator for human reviewers to step in for manual verification.\n",
    "\n",
    "High accuracy and high confidence are ideal, but in practice, there is often a trade-off between the two. While accuracy cannot always be self-assessed, confidence scores can and should be used to prioritize manual verification of low-confidence predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the output of the Azure AI Document Intelligence pre-built layout analysis in Markdown format.\n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the JSON response from the completion and converts it to an Invoice object.\n",
    "response_json = completion.choices[0].message.content\n",
    "invoice = Invoice.from_json(response_json)\n",
    "\n",
    "# Determines the accuracy of the extracted data against the expected values.\n",
    "accuracy = invoice_evaluator.evaluate(invoice)\n",
    "\n",
    "# Determines the confidence of the extracted data against the expected values using the result of the Azure AI Document Intelligence pre-built layout analysis.\n",
    "confidence = evaluate_confidence(invoice.to_dict(), result)\n",
    "\n",
    "# Gets the total execution time of the data extraction process.\n",
    "total_elapsed = di_stopwatch.elapsed + oai_stopwatch.elapsed\n",
    "\n",
    "# Gets the prompt tokens and completion tokens from the completion response.\n",
    "prompt_tokens = completion.usage.prompt_tokens\n",
    "completion_tokens = completion.usage.completion_tokens\n",
    "\n",
    "# Save the output of the data extraction result.\n",
    "extraction_result = DataExtractionResult(invoice.to_dict(), confidence, accuracy, prompt_tokens, completion_tokens, total_elapsed)\n",
    "\n",
    "with open(f\"{working_dir}/samples/extraction/text-based/document-intelligence-phi.{pdf_file_name}.json\", \"w\") as f:\n",
    "    f.write(extraction_result.to_json(indent=4))\n",
    "    \n",
    "# Display the outputs of the data extraction process.\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"Accuracy\": f\"{accuracy['overall'] * 100:.2f}%\",\n",
    "        \"Confidence\": f\"{confidence['_overall'] * 100:.2f}%\",\n",
    "        \"Execution Time\": f\"{total_elapsed:.2f} seconds\",\n",
    "        \"Document Intelligence Execution Time\": f\"{di_stopwatch.elapsed:.2f} seconds\",\n",
    "        \"Phi-3.5-mini Execution Time\": f\"{oai_stopwatch.elapsed:.2f} seconds\",\n",
    "        \"Prompt Tokens\": prompt_tokens,\n",
    "        \"Completion Tokens\": completion_tokens\n",
    "    }\n",
    "])\n",
    "\n",
    "display(Markdown(df.to_markdown(index=False, tablefmt='unsafehtml')))\n",
    "display(Markdown(extraction_comparison(expected.to_dict(), invoice.to_dict(), confidence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
